import pandas as pd                      # For data handling
import matplotlib.pyplot as plt          # For plotting graphs
from sklearn.preprocessing import StandardScaler   # For feature scaling
from sklearn.cluster import KMeans       # K-Means clustering

df = pd.read_csv('sales_data_sample.csv', encoding='unicode_escape')   # Load dataset

df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'])    # Convert dates to datetime format

# Build RFM table (Recency, Frequency, Monetary)
rfm = df.groupby('CUSTOMERNAME').agg({
    'ORDERDATE': lambda x: (df['ORDERDATE'].max() - x.max()).days,   # Recency
    'ORDERNUMBER': 'count',                                           # Frequency
    'SALES': 'sum'                                                    # Monetary
})

rfm.columns = ['Recency', 'Frequency', 'Monetary']   # Rename columns

scaler = StandardScaler()            # Normalize features
data_scaled = scaler.fit_transform(rfm)

sse = []                              # To store SSE for each k

for k in range(1, 11):                # Test k from 1 to 10
    km = KMeans(n_clusters=k, random_state=1)   # Create model
    km.fit(data_scaled)                        # Train model
    sse.append(km.inertia_)                    # Store SSE

# Differences between consecutive SSE values
diff = [sse[i-1] - sse[i] for i in range(1, len(sse))]

best_k = diff.index(max(diff)) + 1     # Find the elbow point

plt.plot(range(1, 11), sse, marker='o')   # Plot elbow curve
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('SSE')
plt.grid(True)
plt.show()

print("Optimal number of clusters (Elbow Method):", best_k)
